# Self-supervised Co-training for Video Representation Learning

## 0.摘要

* 图像和视频的自我监督表示学习的最新进展证明了在数据样本上使用区分对比损失的益处[12，13，27，28，45，59]，例如NCE[24，34]。

* 给定一个数据样本，目标是将其转换版本与数据集中的其他样本区分开来。

  * 这些变换可以是人工的，例如在数据增强[12]中使用的变换，
  * 也可以是自然的，例如来自同一剪辑内的时间片段的视频中出现的变换。

* 本质上，这些借口任务侧重于实例区分：每个数据样本都被视为一个“类”，其目的是将其自身的增强版本与大量其他数据样本或其增强版本区分开来。以这种方式通过实例歧视获得的代表在下游任务中表现出极高的绩效，通常与监督培训取得的效果相当[12，27]。

  

## 1.简介

* 图像和视频的自我监督表示学习的最新进展证明了在数据样本上使用区分对比损失的益处[12，13，27，28，45，59]，例如NCE[24，34]。
* 给定一个数据样本，目标是将其转换版本与数据集中的其他样本区分开来。
  * 这些变换可以是人工的，例如在数据增强[12]中使用的变换，
  * 也可以是自然的，例如来自同一剪辑内的时间片段的视频中出现的变换。
* 本质上，这些借口任务侧重于实例区分：每个数据样本都被视为一个“类”，其目的是将其自身的增强版本与大量其他数据样本或其增强版本区分开来。以这种方式通过实例歧视获得的代表在下游任务中表现出极高的绩效，通常与监督培训取得的效果相当[12，27]。
* 在本文中，我们以自我监督的视频表示学习为目标，并提出了一个问题：**实例区别是否充分利用了数据？我们在两个方面表明答案是否定的**：

