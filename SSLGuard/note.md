# SSLGuard：一种用于自监督学习预训练编码器的水印方案

## 0.摘要

> * 与利用高质量标记数据集实现良好性能的监督学习相比，自监督学习依赖于未标记数据集来预训练强大的编码器，然后可以将其作为各种下游任务的特征提取器。
> * 大量的数据和计算资源消耗使得编码器本身成为模型所有者的宝贵知识产权。最近的研究表明，ML模型的版权受到模型窃取攻击的威胁，这种攻击旨在训练代理模型来模仿给定模型的行为。
> * 这是第一个用于预训练编码器的水印算法。给定一个干净的预训练编码器，SSLGuard将水印注入其中并输出带水印的版本。

## 1.简介

### 出发点

> * 自我监督学习（SSL）被提议通过从未标记的数据集（称为预训练数据集）生成“标签”来解决缺少标记数据的限制，并使用导出的“标签”对编码器进行预训练。
> * 高性能编码器通常由具有足够计算资源的领先AI公司预先训练，并通过云平台共享;
> * 面临威胁：
>   * 成员身份推断攻击（即，通过使用代理编码器离线安装成员身份推断）
>   * 后门攻击（即发布另一个后门编码器）
>   * 对抗样本。
> * 加水印SSL预训练编码器面临内在挑战
>   * 首先，针对分类器的模型水印通常需要在执行之前指定一个目标类，而SSL预训练的编码器没有此类信息。
>   * 其次，SSL预训练编码器的下游任务是灵活的，这挑战了仅适用于一个特定下游任务的传统模型水印方案。

### 作者工作

* 在本文中，我们首先通过模型窃取攻击来量化针对SSL预训练编码器的侵犯版权威胁。
* 然后，我们介绍了SSLGuard，这是第一个用于SSL预训练编码器的水印算法，以保护其版权。**请注意，在这项工作中，我们只考虑图像编码器。**
* 广泛的评估表明，SSLGuard在注入和提取水印方面有效，并且对模型窃取和其他水印移除攻击（如输入噪声、输出扰动、覆盖、模型修剪和微调）具有鲁棒性。

> ####  模型窃取攻击
>
> * 假设对手只能访问SSL预先训练的编码器（即受害者编码器）的黑匣子。对手的目标是构建一个替代编码器来“复制”受害者编码器的功能。
> * 将对手的背景知识描述为两个维度，即代理数据集的分布和代理编码器的架构。
>   * 对手可能知道或可能不知道受害者编码器的预训练数据集。
>   * 假设代理编码器与受害者编码器共享相同的架构。然后，放松这一假设，发现通过利用更大的模型架构，模型窃取攻击的有效性甚至可以提高。
>   * 窃取编码器的成本比从头开始预训练的成本小得多
>
> #### SSLGuard
>
> * 具体来说，给定一个秘密向量，SSLGuard的目标是将基于该秘密向量的水印注入到一个干净的SSL预训练编码器中。SSLGuard的输出包含一个带水印的编码器和一个密钥元组。具体来说，密钥元组由秘密向量、验证数据集和解码器组成。SSLGuard将干净的编码器微调为带水印的编码器。
> * 带水印编码器可以保留干净编码器的效用，并将验证数据集中的样本映射到秘密表示。我们还引入了一个解码器来将这些秘密表示转换为可能位于另一个空间中的秘密向量。对于其他编码器，解码器仅将从验证数据集生成的表示转换为随机向量。
>
> #### 鲁棒性测试
>
> * 对7个数据集（即ImageNet、CIFAR-10、CIFAR-100、STL-10、GTSRB、MNIST和FashionMNIST）和3个编码器预训练算法（即SimCLR、MoCo v2和BYOL）的经验评估表明，SSLGuard可以在不牺牲其性能的情况下成功地向SSL预训练编码器注入/提取水印，并且对模型窃取攻击具有鲁棒性。此外，我们考虑了各种类型的水印去除攻击，包括输入预处理（含噪）、输出扰动（含噪和截断）和模型修改（覆盖、修剪和微调）以“清理”模型。我们的经验表明，SSLGuard在这种情况下仍然有效。

